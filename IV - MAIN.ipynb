{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV - Analyses descriptives et Visualisation : Prix de l'immobilier et Risque d'inondation dans le Gard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports des modules nécessaires à l'execution du notebook\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import folium\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nbformat --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de L'API indicateurs de prix (accès libre)\n",
    "L'API Données foncières permet d'interroger rapidement et librement les indicateurs de prix issus de DV3F à différentes échelles géographiques.\n",
    "Nous appelons l'api pour des premiers graphiques sur la variations des prix à l'échelle départementale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL_API = \"https://apidf-preprod.cerema.fr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'interrogation de l'API\n",
    "def apidf(url_endpoint, token=None):\n",
    "    HEADERS = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    if token:\n",
    "        HEADERS[\"Authorization\"] = \"Token \" + token\n",
    "    response = requests.get(\n",
    "        url_endpoint,\n",
    "        headers=HEADERS,\n",
    "    )  \n",
    "    if response.status_code == 200:\n",
    "      return response.json()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction apidf proposée facilite l'interrogation de l'API Données foncières (en fournissant le jeton si l'accès en restreint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage du endpoint\n",
    "code_insee, nom = \"30189\", \"Nîmes\"\n",
    "url = BASE_URL_API + f\"/indicateurs/dv3f/communes/annuel/{code_insee}\"\n",
    "\n",
    "# Interrogation de l'API et récupération d'un dataframe\n",
    "response  = apidf(url)\n",
    "indicateurs = pd.DataFrame.from_dict(response[\"results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicateurs.head()\n",
    "indicateurs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtre des indicateurs propre à notre étude \n",
    "df = indicateurs[[\"valeurfonc_sum_cod1\",\"valeurfonc_sum_cod111\",\"valeurfonc_sum_cod121\",\n",
    "\"sbati_sum_cod111\",\"sbati_sum_cod121\",\n",
    "\"nbtrans_cod111\",\"nbtrans_cod121\",\n",
    "\"valeurfonc_median_cod111\",\"valeurfonc_median_cod121\",\n",
    "\"sbati_median_cod111\",\"sbati_median_cod121\",\n",
    "\"pxm2_median_apx\",\"pxm2_median_amx\",\"pxm2_median_agx\",\n",
    "\"pxm2_median_mpx\",\"pxm2_median_mmx\",\"pxm2_median_mgx\",]]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse descriptive du marché du logement à Nîmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "# Edition du graphique\n",
    "fig = px.line(indicateurs, \n",
    "             x='annee', \n",
    "             y=['pxm2_median_mmx', 'pxm2_median_amx'], \n",
    "             title = f\"Evolution annuelle du prix médian des logements sur {nom}\", \n",
    "             range_y=[0, 5500],\n",
    "             labels={\"annee\" : \"Année de mutation\", \n",
    "                     \"value\" : \"Prix en €/m2\",},\n",
    "             )\n",
    "noms={\"pxm2_median_mmx\": \"Maison moyenne (entre 90 et 130 m2)\", \n",
    "      \"pxm2_median_amx\": \"Appartement moyen (T3 et T4)\"}\n",
    "fig.update_layout(legend_title_text=\"Prix médian au mètre carré\")\n",
    "fig.for_each_trace(lambda t: t.update(hovertemplate = t.hovertemplate.replace(t.name, noms[t.name]), name=noms[t.name]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nbformat.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prix au mètre carrée reste stable avec une légère hausse en 2023. En prenant en compte l'inflation, le coût de l'immobilier dans le temps diminue. Donc l'immobilier serait plutôt en perte de vitesse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage du endpoint\n",
    "code_insee, nom = \"30189\", \"Nîmes\"\n",
    "url = BASE_URL_API + f\"/indicateurs/dv3f/communes/annuel/{code_insee}\"\n",
    "\n",
    "# Interrogation de l'API et récupération d'un dataframe\n",
    "response  = apidf(url)\n",
    "indicateurs = pd.DataFrame.from_dict(response[\"results\"])\n",
    "\n",
    "# Edition du graphique\n",
    "fig = px.bar(indicateurs, \n",
    "             x='annee', \n",
    "             y=['nbtrans_cod111', 'nbtrans_cod121'], \n",
    "             title = f\"Evolution annuelle du nombre de ventes de logements individuels à {nom}\", \n",
    "             labels={\"annee\" : \"Année de mutation\", \n",
    "                     \"value\" : \"Nombre de ventes\",},\n",
    "             )\n",
    "noms={\"nbtrans_cod111\": \"Maison individuelle\", \n",
    "      \"nbtrans_cod121\": \"Appartement individuel\"}\n",
    "fig.update_layout(legend_title_text=\"Nombre de ventes\")\n",
    "fig.for_each_trace(lambda t: t.update(hovertemplate = t.hovertemplate.replace(t.name, noms[t.name]), name=noms[t.name]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, le nombre de transactions croît à Nîmes. Une légère baisse en 2014 qui peut s'expliquer par la crise de 2008 à 2012 et les risques climatiques. Il y a par la suite un regain dans le nombre de transactions immobilières. Cela peut à certains égards contredire l'idée selon laquelle les risques climatiques ralentissent l'immobilier dans ces régions. \n",
    "Peut-être que Nîmes est moins touchés par ce phénomène.\n",
    "\n",
    "Nous analysons donc Saint-Gilles, une commune au sud de Nîmes qui est plus sujette au risque d'inondation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage du endpoint\n",
    "code_insee, nom = \"30258\", \"Saint-Gilles\"\n",
    "url = BASE_URL_API + f\"/indicateurs/dv3f/communes/annuel/{code_insee}\"\n",
    "\n",
    "# Interrogation de l'API et récupération d'un dataframe\n",
    "response  = apidf(url)\n",
    "indicateurs = pd.DataFrame.from_dict(response[\"results\"])\n",
    "\n",
    "# Edition du graphique\n",
    "fig = px.bar(indicateurs, \n",
    "             x='annee', \n",
    "             y=['nbtrans_cod111', 'nbtrans_cod121'], \n",
    "             title = f\"Evolution annuelle du nombre de ventes de logements individuels à {nom}\", \n",
    "             labels={\"annee\" : \"Année de mutation\", \n",
    "                     \"value\" : \"Nombre de ventes\",},\n",
    "             )\n",
    "noms={\"nbtrans_cod111\": \"Maison individuelle\", \n",
    "      \"nbtrans_cod121\": \"Appartement individuel\"}\n",
    "fig.update_layout(legend_title_text=\"Nombre de ventes\")\n",
    "fig.for_each_trace(lambda t: t.update(hovertemplate = t.hovertemplate.replace(t.name, noms[t.name]), name=noms[t.name]))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saint-Gilles connaît des variations similaires que Nîmes. Le risques climatiques ne ralentirait pas le nombre de transactions immobilière, en tout cas, cela a moins d'effet qu'une crise économique sur le marché immobilier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramétrage du endpoint\n",
    "code_insee, nom = \"30189\", \"Nîmes\"\n",
    "url = BASE_URL_API + f\"/dvf_opendata/mutations/?code_insee={code_insee}&page_size=1000&anneemut_min=2018&codtypbien=111\"\n",
    "\n",
    "# Interrogation de l'API pour récupérer les pages de mutations\n",
    "pages = []\n",
    "\n",
    "while True:\n",
    "    response = apidf(url) \n",
    "    mutations = pd.DataFrame.from_dict(response[\"results\"])\n",
    "    pages.append(mutations)\n",
    "    if not response[\"next\"]:\n",
    "      break\n",
    "    url = response[\"next\"]\n",
    "\n",
    "# concaténation des pages et affichage graphique\n",
    "mutations = pd.concat(pages)\n",
    "mutations[\"valeurfonc\"] = mutations[\"valeurfonc\"].astype(float)\n",
    "fig = px.violin(mutations, \n",
    "                y=\"valeurfonc\", \n",
    "                x=\"anneemut\", \n",
    "                color=\"anneemut\", \n",
    "                box=True, \n",
    "                title = f\"Distribution annuelle des prix des ventes de maison à partir de 2018 à {nom}\", \n",
    "                labels={\"annee\" : \"Année\", \n",
    "                        \"valeurfonc\" : \"Prix en €\",},)\n",
    "fig.update_layout(legend_title_text=\"Année de mutation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribution des logements, qui est similaire à travers les années, montre qu'il n'y a pas de différence flagrante sur le marché de l'immobilier malgré l'augmentation du risque dans ces régions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse descriptive du marché du logement dans le Gard \n",
    "### A- Valeur médiane par commune dans le Gard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons ici une nouvelle dataframe qui collecte toutes les valeurs foncières médiane des communes du Gard.\n",
    "\n",
    "D'abord nous récupérons, grâce au fichiers de l'Insee, tous les codes communes du Gard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the INSEE commune data\n",
    "url = \"https://www.insee.fr/fr/statistiques/fichier/6800675/v_commune_2023.csv\"\n",
    "\n",
    "# Load the CSV file containing the list of communes\n",
    "communes = pd.read_csv(url)\n",
    "print(\"File successfully loaded!\")\n",
    "communes.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les communes du Gard (département 30)\n",
    "gard_communes = communes[communes[\"DEP\"] == \"30\"]\n",
    "\n",
    "# Extraire les codes INSEE\n",
    "codes_communes = gard_communes[\"COM\"].tolist()\n",
    "\n",
    "# Diviser la liste des communes en sous-listes de taille 35\n",
    "chunk_size = 35\n",
    "sub_lists = [codes_communes[i:i + chunk_size] for i in range(0, len(codes_communes), chunk_size)]\n",
    "\n",
    "print(f\"Nombre total de communes dans le Gard : {len(codes_communes)}\")\n",
    "print(f\"Nombre de sous-listes : {len(sub_lists)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons créer des sous listes des 350 codes communes pour alléger le code suivant car l'api s'arrêtait après trop de requête de suite. \n",
    "\n",
    "**Ce code ne doit pas être lancé car il dure environ 30 minutes et les communes se chargent de manière aléatoire au bon vouloir de l'api.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "# Initialisation d'une liste pour stocker les DataFrames\n",
    "dataframes = []\n",
    "\n",
    "for sub_list in sub_lists:\n",
    "    for code_insee in sub_list:\n",
    "        url = BASE_URL_API + f\"/indicateurs/dv3f/communes/annuel/{code_insee}\"\n",
    "\n",
    "        for attempt in range(3):  # Essayer jusqu'à 3 fois\n",
    "            try:\n",
    "                print(f\"Requête pour {code_insee}: {url}\")\n",
    "                response = apidf(url)\n",
    "                break\n",
    "            except ConnectionResetError as e:\n",
    "                print(f\"Erreur de connexion pour {code_insee}: {e}\")\n",
    "                time.sleep(3)\n",
    "            except Exception as e:\n",
    "                print(f\"Autre erreur : {e}\")\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Échec après 3 tentatives pour {code_insee}\")\n",
    "            continue\n",
    "\n",
    "        # Traiter les données en cas de succès\n",
    "        indicateurs_communes = pd.DataFrame.from_dict(response.get(\"results\", []))\n",
    "        if not indicateurs_communes.empty:\n",
    "            val_fonc = indicateurs_communes[indicateurs_communes['annee'] == '2023']\n",
    "            val_fonc_2023 = val_fonc[[\"codgeo\", \"libgeo\", \"valeurfonc_median_cod111\", \"valeurfonc_median_cod121\"]]\n",
    "            dataframes.append(val_fonc_2023)\n",
    "\n",
    "    time.sleep(2)  # Pause entre les groupes pour éviter la surcharge\n",
    "\n",
    "# Combiner les DataFrames\n",
    "final_dataframe = pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "final_dataframe.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc créer une nouvelle dataframe qui se concentre sur les valeurs foncières de 2023. Elle est enregistré en csv pour faciliter les codes suivants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.to_csv(\"/home/onyxia/work/Python-For-Data-Science-Project/final_dataframe.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- Création d'une carte des prix dans le Gard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous cherchons maintenant à créer une carte du Gard qui rendra compte des valeurs fonciers de chaque communes en 2023. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du package Cartiflette \n",
    "!pip install py7zr geopandas openpyxl tqdm s3fs\n",
    "!pip install PyYAML xlrd\n",
    "!pip install git+https://github.com/inseefrlab/cartiflette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cartiflette import carti_download\n",
    "\n",
    "\n",
    "\n",
    "communes_30= carti_download(\n",
    "    values=[\"30\"],\n",
    "    crs=4326,\n",
    "    borders=\"COMMUNE\",\n",
    "    vectorfile_format=\"geojson\",\n",
    "    filter_by=\"DEPARTEMENT\",\n",
    "    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n",
    "    year=2022,\n",
    ")\n",
    "\n",
    "communes_30.crs\n",
    "communes_30 = communes_30.to_crs(2154)\n",
    "communes_30.crs\n",
    "\n",
    "ax = communes_30.boundary.plot()\n",
    "ax.set_axis_off()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons créer grâce à cartiflette le fond de carte du Gard. On va maintenant y ajouter la base de données des valeurs foncières médianes de 2023. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV des valeurs foncières\n",
    "final_dataframe = pd.read_csv(\"final_dataframe.csv\", encoding=\"utf-8\")\n",
    "print(final_dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(communes_30[\"INSEE_COM\"].dtype)  # Vérifier le type de INSEE_COM\n",
    "print(final_dataframe[\"codgeo\"].dtype)  # Vérifier le type de codgeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les types ne correspondant pas, on les change en chaines de caractères. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les colonnes en chaînes de caractères\n",
    "communes_30[\"INSEE_COM\"] = communes_30[\"INSEE_COM\"].astype(str)\n",
    "final_dataframe[\"codgeo\"] = final_dataframe[\"codgeo\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant concaténer les deux bases de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les données géographiques avec les données foncières\n",
    "communes_30 = communes_30.merge(final_dataframe, how=\"left\", left_on=\"INSEE_COM\", right_on=\"codgeo\")\n",
    "\n",
    "print(communes_30.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trace maintenant la carte des prix du Gard pour les maisons individuelles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher la carte avec une coloration en fonction des valeurs foncières\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "communes_30.plot(column=\"valeurfonc_median_cod111\",  # Colonne avec les valeurs foncières\n",
    "                 cmap=\"OrRd\",                      # Colormap (nuances de rouge)\n",
    "                 legend=True,                      # Ajouter une légende\n",
    "                 ax=ax)\n",
    "\n",
    "ax.set_title(\"Carte des valeurs foncières des maisons des communes du Gard (2023)\", fontsize=16)\n",
    "ax.set_axis_off()  # Enlever les axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carte étant un peu vide avec certaine zone vide, on décide de griser les zones sans informations et de faire la moyenne des valeurs foncières des appartements et des maisons pour compléter la carte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Étape 1 : Calculer la moyenne des deux colonnes\n",
    "communes_30[\"valeurfonc_moyenne\"] = (\n",
    "    communes_30[[\"valeurfonc_median_cod111\", \"valeurfonc_median_cod121\"]]\n",
    "    .mean(axis=1, skipna=True)\n",
    ")\n",
    "\n",
    "# Étape 2 : Ajouter une colonne pour marquer les communes sans informations\n",
    "communes_30[\"data_missing\"] = communes_30[\"valeurfonc_moyenne\"].isna()\n",
    "\n",
    "# Étape 3 : Définir les couleurs\n",
    "# Palette de couleurs : communes avec données (bleu -> rouge) et sans données (gris)\n",
    "color_map = communes_30[\"valeurfonc_moyenne\"].apply(\n",
    "    lambda x: \"gray\" if np.isnan(x) else plt.cm.viridis((x - communes_30[\"valeurfonc_moyenne\"].min()) / \n",
    "                                                        (communes_30[\"valeurfonc_moyenne\"].max() - communes_30[\"valeurfonc_moyenne\"].min()))\n",
    ")\n",
    "\n",
    "# Étape 4 : Tracer la carte\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "communes_30.plot(ax=ax, color=color_map)\n",
    "\n",
    "# Ajouter une légende\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Couleur spéciale pour les données manquantes\n",
    "missing_patch = Line2D(\n",
    "    [0], [0], color=\"gray\", lw=4, label=\"Données manquantes\"\n",
    ")\n",
    "\n",
    "# Ajouter des légendes automatiques pour les autres valeurs\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=plt.Normalize(vmin=communes_30[\"valeurfonc_moyenne\"].min(), vmax=communes_30[\"valeurfonc_moyenne\"].max()))\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm, ax=ax, orientation=\"vertical\", fraction=0.03, pad=0.04)\n",
    "cbar.set_label(\"Valeurs foncières moyennes\")\n",
    "\n",
    "ax.legend(handles=[missing_patch], loc=\"lower right\")\n",
    "ax.set_title(\"Carte des valeurs foncières moyennes par commune (Gard)\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Afficher la carte\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans prendre en compte le nord du Gard qui doit être moins attractif, les zones les plus touchés par les risques d'inondations qui sont au sud du Gard(vu sur la carte des risques) ont des valeurs foncières médianes moindre, ce qui traduirait une moindre attractivité de ces zones à risques en 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risque d'inondation et transactions immobilières \n",
    "\n",
    "L'objectif de cette partie est de coupler les données récupéré au travers du processing des différentes sources de données afin de représenter dans un même temps risque d'innondation et transactions immobilières "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cartiflette import carti_download\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#Récupération des geodataframes pour tracer la carte \n",
    "gdf_nv_risque = gpd.read_file(\"/home/onyxia/work/Python-For-Data-Science-Project/II - TRI Shapefile Processing/gdf_nv_risque.geojson\")\n",
    "gdf_type_risque = risk_data = pd.read_csv(\"/home/onyxia/work/Python-For-Data-Science-Project/I - TRI API Processing /Type_inondation_data.csv\")\n",
    "gdf_cours_eau = gpd.read_file(\"/home/onyxia/work/Python-For-Data-Science-Project/II - TRI Shapefile Processing/gdf_cours_eau.geojson\")\n",
    "\n",
    "# Convertir les colonnes de type Timestamp en chaînes de caractères dans gdf_nv_risque\n",
    "for col in gdf_nv_risque.columns:\n",
    "    if gdf_nv_risque[col].dtype == 'datetime64[ms]':\n",
    "        gdf_nv_risque[col] = gdf_nv_risque[col].astype(str)\n",
    "\n",
    "\n",
    "# Charger les données Cartiflette pour les communes du Gard\n",
    "Gard = carti_download(\n",
    "    crs=4326,\n",
    "    values=\"30\",\n",
    "    borders=\"COMMUNE\",\n",
    "    vectorfile_format=\"geojson\",\n",
    "    filter_by=\"DEPARTEMENT\",\n",
    "    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n",
    "    year=2022\n",
    ")\n",
    "\n",
    "# Charger les informations sur la nature des risques\n",
    "gdf_type_risque_grouped = gdf_type_risque.groupby('code_insee')['libelle_risque_long'].apply(\n",
    "    lambda x: ', '.join(x.unique())\n",
    ").reset_index()\n",
    "Gard_type_risque = Gard.merge(gdf_type_risque_grouped, left_on='INSEE_COM', right_on='code_insee', how='left')\n",
    "Gard_type_risque['libelle_risque_long'] = Gard_type_risque['libelle_risque_long'].fillna(\"Pas de risque identifié\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.features import GeoJson, GeoJsonTooltip\n",
    "\n",
    "# Créer une carte Folium centrée sur le Gard\n",
    "m = folium.Map(location=[44.0, 4.0], zoom_start=9, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Ajouter les contours des communes et la nature des risques avec `Gard_with_risks`\n",
    "geojson_communes = folium.GeoJson(\n",
    "    Gard_type_risque,\n",
    "    style_function=lambda x: {\"fillColor\": \"transparent\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0},\n",
    "    highlight_function=lambda x: {\"fillColor\": \"yellow\", \"color\": \"black\", \"weight\": 2, \"fillOpacity\": 0.3},\n",
    "    tooltip=GeoJsonTooltip(\n",
    "        fields=[\"libelle_risque_long\"],  # Afficher la nature des risques\n",
    "        aliases=[\"Nature du risque :\"],  # Texte dans l'info-bulle\n",
    "        localize=True\n",
    "    )\n",
    ")\n",
    "geojson_communes.add_to(m)\n",
    "\n",
    "#Afficher la carte\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.features import GeoJson, GeoJsonTooltip\n",
    "\n",
    "# Créer une carte Folium centrée sur le Gard\n",
    "m = folium.Map(location=[44.0, 4.0], zoom_start=9, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Étape 1 : Ajouter les contours des communes et la nature des risques avec `Gard_with_risks`\n",
    "geojson_communes = folium.GeoJson(\n",
    "    Gard_type_risque,\n",
    "    style_function=lambda x: {\"fillColor\": \"transparent\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0},\n",
    "    highlight_function=lambda x: {\"fillColor\": \"yellow\", \"color\": \"black\", \"weight\": 2, \"fillOpacity\": 0.3},\n",
    "    tooltip=GeoJsonTooltip(\n",
    "        fields=[\"libelle_risque_long\"],  # Afficher la nature des risques\n",
    "        aliases=[\"Nature du risque :\"],  # Texte dans l'info-bulle\n",
    "        localize=True\n",
    "    )\n",
    ")\n",
    "geojson_communes.add_to(m)\n",
    "\n",
    "# Étape 2 : Ajouter les cours d’eau dans le Gard avec `waterways_clipped`\n",
    "geojson_waterways = folium.GeoJson(\n",
    "    gdf_cours_eau,\n",
    "    style_function=lambda x: {\"color\": \"blue\", \"weight\": 1.5, \"fillOpacity\": 0.7},  # Style des cours d'eau\n",
    "    tooltip=GeoJsonTooltip(fields=[], aliases=[])  # Pas d'info-bulle pour les cours d'eau\n",
    ")\n",
    "geojson_waterways.add_to(m)\n",
    "\n",
    "#afficher la carte\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.features import GeoJson, GeoJsonTooltip\n",
    "\n",
    "# Créer une carte Folium centrée sur le Gard\n",
    "m = folium.Map(location=[44.0, 4.0], zoom_start=9, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Étape 1 : Ajouter les polygones des niveaux de risque en arrière-plan (`gdf_nv_risque`)\n",
    "def style_function_risk(feature):\n",
    "    risk_level = feature['properties'].get('typ_inond1', None)\n",
    "    if risk_level == 1:  # Risque faible\n",
    "        color = \"lightblue\"\n",
    "    elif risk_level == 3:  # Risque élevé\n",
    "        color = \"lightcoral\"\n",
    "    else:\n",
    "        color = \"gray\"  # Pas de données\n",
    "    return {\"fillColor\": color, \"color\": \"black\", \"weight\": 0.5, \"fillOpacity\": 0.6}\n",
    "\n",
    "geojson_risks = folium.GeoJson(\n",
    "    gdf_nv_risque,\n",
    "    style_function=style_function_risk  # Appliquer les couleurs basées sur `typ_inond1`\n",
    ")\n",
    "geojson_risks.add_to(m)\n",
    "\n",
    "# Étape 2 : Ajouter les contours des communes avec surlignage et info-bulle (`Gard_with_risks`)\n",
    "geojson_communes = folium.GeoJson(\n",
    "    Gard_type_risque,\n",
    "    style_function=lambda x: {\"fillColor\": \"transparent\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0},\n",
    "    highlight_function=lambda x: {\"fillColor\": \"yellow\", \"color\": \"black\", \"weight\": 2, \"fillOpacity\": 0.3},\n",
    "    tooltip=GeoJsonTooltip(\n",
    "        fields=[\"libelle_risque_long\"],  # Afficher la nature des risques\n",
    "        aliases=[\"Nature du risque :\"],  # Texte dans l'info-bulle\n",
    "        localize=True\n",
    "    )\n",
    ")\n",
    "geojson_communes.add_to(m)\n",
    "\n",
    "# Étape 3 : Ajouter les cours d’eau dans le Gard avec `waterways_clipped`\n",
    "geojson_waterways = folium.GeoJson(\n",
    "    gdf_cours_eau,\n",
    "    style_function=lambda x: {\"color\": \"blue\", \"weight\": 1.5, \"fillOpacity\": 0.7}\n",
    ")\n",
    "geojson_waterways.add_to(m)\n",
    "\n",
    "# Étape 4 : Ajouter une légende\n",
    "legend_html = \"\"\"\n",
    "<div style=\"\n",
    "    position: fixed;\n",
    "    bottom: 50px;\n",
    "    left: 50px;\n",
    "    width: 250px;\n",
    "    background-color: white;\n",
    "    z-index:9999;\n",
    "    padding: 10px;\n",
    "    border: 1px solid gray;\n",
    "\">\n",
    "    <h4>Légende</h4>\n",
    "    <i style=\"background: lightblue; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Risque faible<br>\n",
    "    <i style=\"background: lightgreen; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Risque modéré<br>\n",
    "    <i style=\"background: lightcoral; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Risque élevé<br>\n",
    "    <i style=\"border: 1px solid black; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Bordure des communes<br>\n",
    "    <i style=\"background: blue; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Cours d'eau<br>\n",
    "</div>\n",
    "\"\"\"\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "#afficher la carte\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous cherchons à évaluer l'interconnection entre les deux sources de données sur les inondations \n",
    "\n",
    "gdf_nv_risque_projected = gdf_nv_risque.to_crs(epsg=2154)  # CRS projeté\n",
    "Gard_type_risque_projected = Gard_type_risque.to_crs(epsg=2154)\n",
    "\n",
    "#Filtrer les zones avec une nature de risque déterminée\n",
    "Gard_with_valid_risks = Gard_type_risque_projected[Gard_type_risque_projected['libelle_risque_long'] != \"Pas de risque identifié\"]\n",
    "\n",
    "#la fonction area permet de déterminer la superficie totale des zones à risque d'inondation dans le Gard. \n",
    "gdf_nv_risque_projected['area'] = gdf_nv_risque_projected.geometry.area\n",
    "total_area = gdf_nv_risque_projected['area'].sum()\n",
    "\n",
    "#Jointure spaciale afin de déterminer les zones de chevauchement entre nature et niveau de risque \n",
    "intersections = gpd.overlay(Gard_with_valid_risks, gdf_nv_risque_projected, how=\"intersection\")\n",
    "\n",
    "#déterminer la superficie totale des intersections\n",
    "intersections['area'] = intersections.geometry.area\n",
    "intersected_area = intersections['area'].sum()\n",
    "\n",
    "#Finalement, nous calculons le le pourcentage\n",
    "percentage_intersection = (intersected_area / total_area) * 100\n",
    "\n",
    "print(f\"Le Pourcentage d'intersection entre territoire avec un niveau de risque supérieur ou égal à un et un libellé de risque est de {percentage_intersection:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation : transactions immobilières et Risque d'inondation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.features import GeoJson, GeoJsonTooltip\n",
    "from folium.plugins import MarkerCluster\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf_trans_immo = gpd.read_file('/home/onyxia/work/Python-For-Data-Science-Project/III - DVF Processing/gdf_trans_immo.geojson')\n",
    "\n",
    "# Créer une carte Folium centrée sur le Gard\n",
    "m = folium.Map(location=[44.0, 4.0], zoom_start=9, tiles=\"cartodbpositron\")\n",
    "\n",
    "# Étape 1 : Ajouter les polygones des niveaux de risque (`gdf_nv_risque`)\n",
    "def style_function_risk(feature):\n",
    "    risk_level = feature['properties'].get('typ_inond1', None)\n",
    "    if risk_level == 1:  # Risque faible\n",
    "        color = \"lightblue\"\n",
    "    elif risk_level == 3:  # Risque élevé\n",
    "        color = \"lightcoral\"\n",
    "    else:\n",
    "        color = \"gray\"  # Pas de données\n",
    "    return {\"fillColor\": color, \"color\": \"black\", \"weight\": 0.5, \"fillOpacity\": 0.6}\n",
    "\n",
    "geojson_risks = folium.GeoJson(\n",
    "    gdf_nv_risque,\n",
    "    style_function=style_function_risk\n",
    ")\n",
    "geojson_risks.add_to(m)\n",
    "\n",
    "# Étape 2 : Ajouter les contours des communes (`Gard_with_risks`)\n",
    "geojson_communes = folium.GeoJson(\n",
    "    Gard_type_risque,\n",
    "    style_function=lambda x: {\"fillColor\": \"transparent\", \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0},\n",
    "    )\n",
    "\n",
    "geojson_communes.add_to(m)\n",
    "\n",
    "# Étape 3 : Ajouter les cours d’eau dans le Gard (`waterways_clipped`)\n",
    "geojson_waterways = folium.GeoJson(\n",
    "    gdf_cours_eau,\n",
    "    style_function=lambda x: {\"color\": \"blue\", \"weight\": 1.5, \"fillOpacity\": 0.7}\n",
    ")\n",
    "geojson_waterways.add_to(m)\n",
    "\n",
    "# Étape 4 : Ajouter les points des transactions immobilières (`gdf_trans_immo`) avec un MarkerCluster\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "for _, row in gdf_trans_immo.iterrows():\n",
    "    # Vérifier que la géométrie est un Point\n",
    "    if row.geometry.geom_type == \"Point\":\n",
    "        # Extraire les informations pour la tooltip\n",
    "        valeurfonc = row.get(\"properties.valeurfonc\", \"Non disponible\")\n",
    "        datemut = row.get(\"properties.datemut\", \"Non disponible\")\n",
    "        sbati = row.get(\"properties.sbati\", \"Non disponible\")\n",
    "        libtypbien = row.get(\"properties.libtypbien\", \"Non disponible\")\n",
    "\n",
    "        # Ajouter le marqueur avec la tooltip\n",
    "        folium.Marker(\n",
    "            location=[row.geometry.y, row.geometry.x],\n",
    "            tooltip=(\n",
    "                f\"<b>Valeur foncière :</b> {valeurfonc}<br>\"\n",
    "                f\"<b>Date de transaction :</b> {datemut}<br>\"\n",
    "                f\"<b>Nombre de m² :</b> {sbati}<br>\"\n",
    "                f\"<b>Type de propriété :</b> {libtypbien}\"\n",
    "            )\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "# Étape 5 : Ajouter une légende\n",
    "legend_html = \"\"\"\n",
    "<div style=\"\n",
    "    position: fixed;\n",
    "    bottom: 50px;\n",
    "    left: 50px;\n",
    "    width: 250px;\n",
    "    background-color: white;\n",
    "    z-index:9999;\n",
    "    padding: 10px;\n",
    "    border: 1px solid gray;\n",
    "\">\n",
    "    <h4>Légende</h4>\n",
    "    <i style=\"background: lightblue; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Risque faible<br>\n",
    "    <i style=\"background: lightcoral; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Risque élevé<br>\n",
    "    <i style=\"border: 1px solid black; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Bordure des communes<br>\n",
    "    <i style=\"background: blue; width: 15px; height: 15px; float: left; margin-right: 5px;\"></i> Cours d'eau<br>\n",
    "</div>\n",
    "\"\"\"\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "#Afficher la carte\n",
    "print(\"Carte combinée générée et sauvegardée dans 'carte_transaction_risque.html'.\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'étape suivante consiste en la régression linéaire à partir du fichier géospatial des transactions immobilières et celles des zones à risques dans le Gard : \n",
    "\n",
    "Pour ce faire, il était souhaitable d'ajouter le niveau de risque présent dans la geodataframe 'gdf_nv_risque' à la géodataframe 'gdf_trans_immo' contenant les valorisation foncières et leurs emplacement géographique pour marquer le niveau de risque d'inondation à chaque transaction. Cependant, nous n'avons pas réussi à réaliser la jointure spatiale de ces deux geodataframe après de multiples tentatives que vous trouverez ci dessous : \n",
    "\n",
    "**code tentative 1 : avec la fonction sjoin**\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import json\n",
    "\n",
    "from shapely.geometry import shape\n",
    "\n",
    "\n",
    "Charger les données des transactions\n",
    "\n",
    "df = pd.read_csv('/home/onyxia/work/Python-For-Data-Science-Project/DVF Processing/transactions_dvf_gard_filtre.zip')\n",
    "\n",
    "Convertir les chaînes de caractères en listes JSON\n",
    "\n",
    "df[\"geometry.coordinates\"] = df[\"geometry.coordinates\"].apply(json.loads)  # Ne pas exécuter plusieurs fois si déjà converti\n",
    "\n",
    "Créer des objets géométriques Shapely\n",
    "\n",
    "df[\"geometry\"] = df[\"geometry.coordinates\"].apply(\n",
    "    lambda coords: shape({\"type\": \"MultiPolygon\", \"coordinates\": coords})\n",
    ")\n",
    "\n",
    "gdf_immo = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:2154\")  # CRS projeté pour calculs précis\n",
    "\n",
    "Harmoniser les systèmes de coordonnées\n",
    "\n",
    "if gdf_immo.crs != gdf_nv_risque.crs:\n",
    "\n",
    "    gdf_nv_risque = gdf_nv_risque.to_crs(gdf_immo.crs)\n",
    "\n",
    "Nettoyer les géométries\n",
    "\n",
    "gdf_immo = gdf_immo[gdf_immo.geometry.notnull()]\n",
    "\n",
    "gdf_nv_risque = gdf_nv_risque[gdf_nv_risque.geometry.notnull()]\n",
    "\n",
    "gdf_nv_risque['geometry'] = gdf_nv_risque.geometry.buffer(0)  # Réparer les géométries si nécessaire\n",
    "\n",
    "Effectuer la jointure spatiale\n",
    "\n",
    "gdf_with_risk = gpd.sjoin(\n",
    "    gdf_immo,                         # Points des transactions\n",
    "    gdf_nv_risque[['geometry', 'typ_inond1']],  # Polygones avec niveaux de risque\n",
    "    how=\"left\",                             # Conserve toutes les transactions\n",
    "    predicate=\"within\"                      # Associe les points contenus dans les polygones\n",
    ")\n",
    "\n",
    "\n",
    "Ajouter une valeur par défaut pour les transactions hors zones de risque\n",
    "\n",
    "gdf_with_risk['typ_inond1'] = gdf_with_risk['typ_inond1'].fillna(0)\n",
    "\n",
    "Renommer la colonne pour clarifier\n",
    "\n",
    "gdf_with_risk = gdf_with_risk.rename(columns={\"typ_inond1\": \"niveau_risque_inondation\"})\n",
    "\n",
    "Supprimer les colonnes inutiles\n",
    "\n",
    "gdf_with_risk = gdf_with_risk.drop(columns=[\"index_right\"], errors=\"ignore\")\n",
    "\n",
    "Afficher un aperçu des données jointes\n",
    "\n",
    "print(gdf_with_risk.head())\n",
    "\n",
    "Sauvegarder le résultat\n",
    "\n",
    "gdf_with_risk.to_file(\"transactions_avec_risque.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(\"GeoDataFrame sauvegardée dans 'transactions_avec_risque.geojson'.\")\n",
    "\n",
    "**code tentative 2 : avec la fonction shapely contains** \n",
    "\n",
    "Dans ce code, nous avions pu identifier que l'erreur pouvais consister au fait que les geodata étaient exprimés d'un coté par des (multi)polygon et de l'autre par des points, nous sommes donc revenu au fichier initial de transactions immobilières (ici df) dont les geodata étaient encodées sous forme de (multi)polygon. \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import json\n",
    "\n",
    "from shapely.geometry import shape\n",
    "\n",
    "Charger les données des transactions\n",
    "\n",
    "df = pd.read_csv('/home/onyxia/work/Python-For-Data-Science-Project/DVF Processing/transactions_dvf_gard_filtre.zip')\n",
    "\n",
    "Convertir les chaînes de caractères en listes JSON\n",
    "\n",
    "df[\"geometry.coordinates\"] = df[\"geometry.coordinates\"].apply(json.loads)  # Ne pas exécuter plusieurs fois si déjà converti\n",
    "\n",
    "Créer des objets géométriques Shapely\n",
    "\n",
    "df[\"geometry\"] = df[\"geometry.coordinates\"].apply(\n",
    "    lambda coords: shape({\"type\": \"MultiPolygon\", \"coordinates\": coords})\n",
    ")\n",
    "\n",
    "gdf_immo = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:2154\")  # CRS projeté pour calculs précis\n",
    "\n",
    "Harmoniser les systèmes de coordonnées\n",
    "\n",
    "if gdf_immo.crs != gdf_nv_risque.crs:\n",
    "\n",
    "    gdf_nv_risque = gdf_nv_risque.to_crs(gdf_immo.crs)\n",
    "\n",
    "Nettoyer les géométries\n",
    "\n",
    "gdf_immo = gdf_immo[gdf_immo.geometry.notnull()]\n",
    "\n",
    "gdf_nv_risque = gdf_nv_risque[gdf_nv_risque.geometry.notnull()]\n",
    "\n",
    "Réparer les géométries si nécessaire\n",
    "\n",
    "gdf_nv_risque['geometry'] = gdf_nv_risque.geometry.buffer(0)\n",
    "\n",
    "Ajouter une colonne pour stocker le niveau de risque\n",
    "\n",
    "def get_risk_level(point, risk_polygons):\n",
    "    \"\"\"\n",
    "    Retourne le niveau de risque pour un point donné en vérifiant son inclusion dans les polygones de risque.\n",
    "    \"\"\"\n",
    "    for _, row in risk_polygons.iterrows():\n",
    "        if row.geometry.contains(point):\n",
    "            return row['typ_inond1']  # Retourner le niveau de risque si le point est contenu dans le polygone\n",
    "    return 0  # Aucun risque si le point n'est dans aucun polygone\n",
    "\n",
    "Calculer le niveau de risque pour chaque transaction\n",
    "\n",
    "gdf_immo['niveau_risque_inondation'] = gdf_immo.geometry.apply(lambda point: get_risk_level(point, gdf_nv_risque))\n",
    "\n",
    "Afficher un aperçu des données jointes\n",
    "\n",
    "print(gdf_immo[['geometry', 'niveau_risque_inondation']].head())\n",
    "\n",
    "Sauvegarder le résultat si nécessaire\n",
    "\n",
    "gdf_immo.to_file(\"transactions_avec_risque.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(\"GeoDataFrame sauvegardée dans 'transactions_avec_risque.geojson'.\")\n",
    "\n",
    "Ainsi, la tentative de mise en évidence de la décote lié au niveau de risque d'inondation dans le Gard a été soldée par un échec, comme nous n'avons pas réussi à coupler à temps le niveau de risque d'inondation aux transactions immobilières. \n",
    "Nous avons quand bien même tenté de vous signifier notre démarche scientifique dans la forme qu'elle comptait prendre ci dessous. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation quantitative\n",
    "\n",
    "Cette section vient compléter l'analyse exploratoire menée plus haut pour essayer d'offrir une modeste quantification de la relation entre risque d'inondations et prix de l'immobilier, sans essayer d'obtenir une interprétation qui soit causale. \n",
    "\n",
    "Pour ce faire, nous nous reposons sur un regroupement de données cross-sectionnelles (*pooled cross-sectional* en anglais) que nous avons pu assembler à partir des bases de données DVF et Géorisque. \n",
    "Ces données comprennent notamment les variables suivantes:\n",
    "- La valeur à laquelle s'est déroulée la transaction immobilière, que nous ajusterons de l'inflation.\n",
    "- Le niveau de risque inhérent à la position géographique du bien, qui est encodé entre trois niveaux de risques: faible, moyen et élevé.\n",
    "- La surface en mètre carrée du bien.\n",
    "\n",
    "Nous estimerons ainsi l'équation économétrique suivante:\n",
    "\n",
    "$ Prix = \\beta_0 + \\beta_1*R_{élevé} + \\beta_2*R_{moyen} + \\beta_3*Surface + \\epsilon $\n",
    "\n",
    "Avec:\n",
    "- $Prix$, la valeur de la transaction immobilière en euro constant de 2015. Nous faisons cet ajustement pour isoler l'effet de l'inflation et donc mieux capturer les interactions liées aux risques d'inondation. De plus, nous avons exclu de la base de données les observations où les valeurs de transactions étaient supérieures au 95ème quantile ou inférieure au 5ème quantile. Ceci permet de se séparer des valeurs aberrantes qui pourraient avoir un effet disproportionné sur nos coefficients de régression.\n",
    "- $R_{élevé}$ et $R_{moyen}$ sont nos variables binaires (*dummies*) liés au niveau de risque du bien immobilier. Le niveau de référence pour de ces *dummies* est le risque de niveau faible.\n",
    "- Et pour finir, $Surface$ correspond à la surface en mètre carré du bien immobilier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cette modélisation fait également référence au prix en euro constant, que nous souhaitions capturer afin de prendre en compte l'inflation dans l'évolution des prix, que nous souhaitions calculer à partir du notebook `Calcul des prix en euro constant.ipynb` mis en annexe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
